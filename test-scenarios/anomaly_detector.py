#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¼‚å¸¸æ£€æµ‹æ¨¡æ‹Ÿå™¨
æ¨¡æ‹Ÿå„ç§å¼‚å¸¸æ£€æµ‹åœºæ™¯ï¼ŒåŒ…æ‹¬æ—¶é—´åºåˆ—å¼‚å¸¸ã€ç»Ÿè®¡å¼‚å¸¸ã€æ¨¡å¼å¼‚å¸¸ç­‰
ç”¨äºAIOpsæµ‹è¯•åœºæ™¯
"""

import argparse
import json
import random
import time
import numpy as np
from datetime import datetime, timedelta
from typing import Dict, List, Any, Tuple
import os
from enum import Enum
from dataclasses import dataclass

class AnomalyType(Enum):
    """å¼‚å¸¸ç±»å‹æšä¸¾"""
    SPIKE = "spike"  # å°–å³°å¼‚å¸¸
    DIP = "dip"  # ä¸‹é™å¼‚å¸¸
    TREND = "trend"  # è¶‹åŠ¿å¼‚å¸¸
    SEASONAL = "seasonal"  # å­£èŠ‚æ€§å¼‚å¸¸
    OUTLIER = "outlier"  # ç¦»ç¾¤ç‚¹å¼‚å¸¸
    PATTERN = "pattern"  # æ¨¡å¼å¼‚å¸¸
    DRIFT = "drift"  # æ¼‚ç§»å¼‚å¸¸
    NOISE = "noise"  # å™ªå£°å¼‚å¸¸

class Severity(Enum):
    """å¼‚å¸¸ä¸¥é‡ç¨‹åº¦æšä¸¾"""
    LOW = "low"
    MEDIUM = "medium"
    HIGH = "high"
    CRITICAL = "critical"

@dataclass
class AnomalyEvent:
    """å¼‚å¸¸äº‹ä»¶æ•°æ®ç±»"""
    timestamp: datetime
    anomaly_type: AnomalyType
    severity: Severity
    metric_name: str
    expected_value: float
    actual_value: float
    deviation_score: float
    confidence: float
    description: str
    context: Dict[str, Any]

class AnomalyDetector:
    """å¼‚å¸¸æ£€æµ‹æ¨¡æ‹Ÿå™¨"""
    
    def __init__(self, duration: int = 300, detection_interval: int = 30):
        """
        åˆå§‹åŒ–å¼‚å¸¸æ£€æµ‹å™¨
        
        Args:
            duration: æ¨¡æ‹Ÿè¿è¡Œæ—¶é•¿(ç§’)
            detection_interval: æ£€æµ‹é—´éš”(ç§’)
        """
        self.duration = duration
        self.detection_interval = detection_interval
        self.start_time = datetime.now()
        self.anomalies = []
        self.metrics_history = []
        self.running = False
        
        # åŸºçº¿é…ç½®
        self.baselines = {
            'cpu_usage': {'mean': 45.0, 'std': 15.0, 'min': 0, 'max': 100},
            'memory_usage': {'mean': 65.0, 'std': 20.0, 'min': 0, 'max': 100},
            'disk_usage': {'mean': 70.0, 'std': 10.0, 'min': 0, 'max': 100},
            'network_throughput': {'mean': 500.0, 'std': 200.0, 'min': 0, 'max': 2000},
            'response_time': {'mean': 150.0, 'std': 50.0, 'min': 0, 'max': 5000},
            'error_rate': {'mean': 2.0, 'std': 1.5, 'min': 0, 'max': 100},
            'transaction_count': {'mean': 1000.0, 'std': 300.0, 'min': 0, 'max': 5000}
        }
        
        # å¼‚å¸¸æ£€æµ‹é˜ˆå€¼
        self.thresholds = {
            'z_score': 2.5,  # Z-scoreé˜ˆå€¼
            'iqr_multiplier': 1.5,  # IQRå€æ•°
            'percentage_change': 50.0,  # ç™¾åˆ†æ¯”å˜åŒ–é˜ˆå€¼
            'confidence_threshold': 0.8  # ç½®ä¿¡åº¦é˜ˆå€¼
        }
    
    def generate_normal_metrics(self) -> Dict[str, float]:
        """
        ç”Ÿæˆæ­£å¸¸çš„æŒ‡æ ‡æ•°æ®
        
        Returns:
            æ­£å¸¸æŒ‡æ ‡æ•°æ®å­—å…¸
        """
        metrics = {}
        current_time = datetime.now()
        
        for metric_name, baseline in self.baselines.items():
            # åŸºç¡€å€¼
            base_value = np.random.normal(baseline['mean'], baseline['std'])
            
            # æ·»åŠ æ—¶é—´ç›¸å…³çš„å‘¨æœŸæ€§å˜åŒ–
            hour = current_time.hour
            if metric_name in ['cpu_usage', 'memory_usage', 'transaction_count']:
                # å·¥ä½œæ—¶é—´è´Ÿè½½æ›´é«˜
                if 9 <= hour <= 17:
                    base_value *= random.uniform(1.2, 1.5)
                elif 18 <= hour <= 22:
                    base_value *= random.uniform(1.0, 1.2)
                else:
                    base_value *= random.uniform(0.7, 1.0)
            
            # æ·»åŠ éšæœºå™ªå£°
            noise = np.random.normal(0, baseline['std'] * 0.1)
            value = base_value + noise
            
            # ç¡®ä¿å€¼åœ¨åˆç†èŒƒå›´å†…
            value = max(baseline['min'], min(baseline['max'], value))
            metrics[metric_name] = round(value, 2)
        
        return metrics
    
    def inject_anomaly(self, metrics: Dict[str, float], anomaly_type: AnomalyType) -> Dict[str, float]:
        """
        å‘æŒ‡æ ‡æ•°æ®ä¸­æ³¨å…¥å¼‚å¸¸
        
        Args:
            metrics: åŸå§‹æŒ‡æ ‡æ•°æ®
            anomaly_type: å¼‚å¸¸ç±»å‹
            
        Returns:
            åŒ…å«å¼‚å¸¸çš„æŒ‡æ ‡æ•°æ®
        """
        anomalous_metrics = metrics.copy()
        metric_name = random.choice(list(metrics.keys()))
        baseline = self.baselines[metric_name]
        original_value = metrics[metric_name]
        
        if anomaly_type == AnomalyType.SPIKE:
            # å°–å³°å¼‚å¸¸ï¼šå€¼çªç„¶å¢å¤§
            multiplier = random.uniform(2.0, 5.0)
            anomalous_value = min(baseline['max'], original_value * multiplier)
            
        elif anomaly_type == AnomalyType.DIP:
            # ä¸‹é™å¼‚å¸¸ï¼šå€¼çªç„¶å‡å°
            multiplier = random.uniform(0.1, 0.5)
            anomalous_value = max(baseline['min'], original_value * multiplier)
            
        elif anomaly_type == AnomalyType.OUTLIER:
            # ç¦»ç¾¤ç‚¹å¼‚å¸¸ï¼šè¿œç¦»æ­£å¸¸èŒƒå›´çš„å€¼
            if random.random() < 0.5:
                anomalous_value = baseline['mean'] + baseline['std'] * random.uniform(4, 6)
            else:
                anomalous_value = baseline['mean'] - baseline['std'] * random.uniform(4, 6)
            anomalous_value = max(baseline['min'], min(baseline['max'], anomalous_value))
            
        elif anomaly_type == AnomalyType.TREND:
            # è¶‹åŠ¿å¼‚å¸¸ï¼šæŒç»­ä¸Šå‡æˆ–ä¸‹é™
            trend_direction = random.choice([1, -1])
            trend_magnitude = random.uniform(0.1, 0.3)
            anomalous_value = original_value * (1 + trend_direction * trend_magnitude)
            anomalous_value = max(baseline['min'], min(baseline['max'], anomalous_value))
            
        elif anomaly_type == AnomalyType.DRIFT:
            # æ¼‚ç§»å¼‚å¸¸ï¼šåŸºçº¿ç¼“æ…¢å˜åŒ–
            drift_amount = random.uniform(0.05, 0.15) * baseline['mean']
            drift_direction = random.choice([1, -1])
            anomalous_value = original_value + drift_direction * drift_amount
            anomalous_value = max(baseline['min'], min(baseline['max'], anomalous_value))
            
        else:
            # é»˜è®¤ä¸ºå™ªå£°å¼‚å¸¸
            noise_multiplier = random.uniform(2, 4)
            noise = np.random.normal(0, baseline['std'] * noise_multiplier)
            anomalous_value = original_value + noise
            anomalous_value = max(baseline['min'], min(baseline['max'], anomalous_value))
        
        anomalous_metrics[metric_name] = round(anomalous_value, 2)
        return anomalous_metrics, metric_name, original_value, anomalous_value
    
    def calculate_z_score(self, value: float, metric_name: str) -> float:
        """
        è®¡ç®—Z-score
        
        Args:
            value: å½“å‰å€¼
            metric_name: æŒ‡æ ‡åç§°
            
        Returns:
            Z-scoreå€¼
        """
        baseline = self.baselines[metric_name]
        return abs(value - baseline['mean']) / baseline['std']
    
    def calculate_deviation_score(self, expected: float, actual: float) -> float:
        """
        è®¡ç®—åå·®åˆ†æ•°
        
        Args:
            expected: æœŸæœ›å€¼
            actual: å®é™…å€¼
            
        Returns:
            åå·®åˆ†æ•° (0-100)
        """
        if expected == 0:
            return 100.0 if actual != 0 else 0.0
        
        deviation = abs(actual - expected) / expected * 100
        return min(100.0, deviation)
    
    def detect_anomalies(self, metrics: Dict[str, float]) -> List[AnomalyEvent]:
        """
        æ£€æµ‹æŒ‡æ ‡ä¸­çš„å¼‚å¸¸
        
        Args:
            metrics: æŒ‡æ ‡æ•°æ®
            
        Returns:
            æ£€æµ‹åˆ°çš„å¼‚å¸¸äº‹ä»¶åˆ—è¡¨
        """
        anomalies = []
        current_time = datetime.now()
        
        for metric_name, value in metrics.items():
            baseline = self.baselines[metric_name]
            expected_value = baseline['mean']
            
            # Z-scoreæ£€æµ‹
            z_score = self.calculate_z_score(value, metric_name)
            
            if z_score > self.thresholds['z_score']:
                # ç¡®å®šå¼‚å¸¸ç±»å‹
                if value > expected_value * 2:
                    anomaly_type = AnomalyType.SPIKE
                elif value < expected_value * 0.5:
                    anomaly_type = AnomalyType.DIP
                else:
                    anomaly_type = AnomalyType.OUTLIER
                
                # ç¡®å®šä¸¥é‡ç¨‹åº¦
                if z_score > 4:
                    severity = Severity.CRITICAL
                elif z_score > 3:
                    severity = Severity.HIGH
                elif z_score > 2.5:
                    severity = Severity.MEDIUM
                else:
                    severity = Severity.LOW
                
                # è®¡ç®—ç½®ä¿¡åº¦
                confidence = min(1.0, z_score / 5.0)
                
                # è®¡ç®—åå·®åˆ†æ•°
                deviation_score = self.calculate_deviation_score(expected_value, value)
                
                # åˆ›å»ºå¼‚å¸¸äº‹ä»¶
                anomaly = AnomalyEvent(
                    timestamp=current_time,
                    anomaly_type=anomaly_type,
                    severity=severity,
                    metric_name=metric_name,
                    expected_value=expected_value,
                    actual_value=value,
                    deviation_score=deviation_score,
                    confidence=confidence,
                    description=f"{metric_name}å¼‚å¸¸: æœŸæœ›å€¼{expected_value:.2f}, å®é™…å€¼{value:.2f}, Z-score: {z_score:.2f}",
                    context={
                        'z_score': z_score,
                        'baseline_mean': baseline['mean'],
                        'baseline_std': baseline['std'],
                        'detection_method': 'z_score'
                    }
                )
                
                anomalies.append(anomaly)
        
        return anomalies
    
    def generate_anomaly_patterns(self) -> List[Dict[str, Any]]:
        """
        ç”Ÿæˆå¼‚å¸¸æ¨¡å¼æ•°æ®
        
        Returns:
            å¼‚å¸¸æ¨¡å¼åˆ—è¡¨
        """
        patterns = []
        
        # æ¨¡å¼1: è¿é”ååº”å¼‚å¸¸
        if random.random() < 0.3:
            patterns.append({
                'type': 'cascade_failure',
                'description': 'è¿é”æ•…éšœæ¨¡å¼',
                'affected_metrics': ['cpu_usage', 'memory_usage', 'response_time'],
                'duration': random.randint(60, 300),
                'severity': random.choice(['medium', 'high', 'critical'])
            })
        
        # æ¨¡å¼2: å‘¨æœŸæ€§å¼‚å¸¸
        if random.random() < 0.2:
            patterns.append({
                'type': 'periodic_anomaly',
                'description': 'å‘¨æœŸæ€§å¼‚å¸¸æ¨¡å¼',
                'period': random.choice([60, 300, 900]),  # 1åˆ†é’Ÿã€5åˆ†é’Ÿã€15åˆ†é’Ÿ
                'affected_metrics': [random.choice(list(self.baselines.keys()))],
                'amplitude': random.uniform(1.5, 3.0)
            })
        
        # æ¨¡å¼3: æ¸è¿›å¼å¼‚å¸¸
        if random.random() < 0.25:
            patterns.append({
                'type': 'gradual_degradation',
                'description': 'æ¸è¿›å¼æ€§èƒ½ä¸‹é™',
                'affected_metrics': ['response_time', 'error_rate'],
                'degradation_rate': random.uniform(0.01, 0.05),
                'duration': random.randint(300, 1800)
            })
        
        return patterns
    
    def simulate_real_world_scenarios(self) -> Dict[str, Any]:
        """
        æ¨¡æ‹ŸçœŸå®ä¸–ç•Œçš„å¼‚å¸¸åœºæ™¯
        
        Returns:
            åœºæ™¯ä¿¡æ¯å­—å…¸
        """
        scenarios = [
            {
                'name': 'memory_leak',
                'description': 'å†…å­˜æ³„æ¼å¯¼è‡´ç³»ç»Ÿæ€§èƒ½ä¸‹é™',
                'affected_metrics': {'memory_usage': 'increasing', 'response_time': 'increasing'},
                'duration': random.randint(600, 1800),
                'probability': 0.15
            },
            {
                'name': 'ddos_attack',
                'description': 'DDoSæ”»å‡»å¯¼è‡´ç½‘ç»œæ‹¥å¡',
                'affected_metrics': {'network_throughput': 'spike', 'response_time': 'spike', 'error_rate': 'spike'},
                'duration': random.randint(300, 900),
                'probability': 0.1
            },
            {
                'name': 'database_slowdown',
                'description': 'æ•°æ®åº“æŸ¥è¯¢æ€§èƒ½ä¸‹é™',
                'affected_metrics': {'response_time': 'increasing', 'cpu_usage': 'increasing'},
                'duration': random.randint(180, 600),
                'probability': 0.2
            },
            {
                'name': 'cache_miss_storm',
                'description': 'ç¼“å­˜å¤±æ•ˆå¯¼è‡´çš„æ€§èƒ½é—®é¢˜',
                'affected_metrics': {'response_time': 'spike', 'cpu_usage': 'spike', 'transaction_count': 'decreasing'},
                'duration': random.randint(120, 300),
                'probability': 0.12
            },
            {
                'name': 'disk_io_bottleneck',
                'description': 'ç£ç›˜I/Oç“¶é¢ˆ',
                'affected_metrics': {'disk_usage': 'spike', 'response_time': 'increasing'},
                'duration': random.randint(240, 720),
                'probability': 0.18
            }
        ]
        
        active_scenarios = []
        for scenario in scenarios:
            if random.random() < scenario['probability']:
                active_scenarios.append(scenario)
        
        return {
            'active_scenarios': active_scenarios,
            'scenario_count': len(active_scenarios)
        }
    
    def run_detection(self, export_file: str = None, inject_anomalies: bool = True):
        """
        è¿è¡Œå¼‚å¸¸æ£€æµ‹æ¨¡æ‹Ÿ
        
        Args:
            export_file: å¯¼å‡ºæ–‡ä»¶è·¯å¾„
            inject_anomalies: æ˜¯å¦æ³¨å…¥å¼‚å¸¸
        """
        print(f"ğŸ” å¯åŠ¨å¼‚å¸¸æ£€æµ‹æ¨¡æ‹Ÿå™¨")
        print(f"æ¨¡æ‹Ÿæ—¶é•¿: {self.duration}ç§’")
        print(f"æ£€æµ‹é—´éš”: {self.detection_interval}ç§’")
        print(f"å¼‚å¸¸æ³¨å…¥: {'å¯ç”¨' if inject_anomalies else 'ç¦ç”¨'}")
        print(f"å¼€å§‹æ—¶é—´: {self.start_time.strftime('%Y-%m-%d %H:%M:%S')}")
        
        self.running = True
        end_time = self.start_time + timedelta(seconds=self.duration)
        
        # ç”Ÿæˆå¼‚å¸¸æ¨¡å¼
        patterns = self.generate_anomaly_patterns()
        scenarios = self.simulate_real_world_scenarios()
        
        print(f"ç”Ÿæˆå¼‚å¸¸æ¨¡å¼: {len(patterns)}ä¸ª")
        print(f"æ¿€æ´»åœºæ™¯: {scenarios['scenario_count']}ä¸ª")
        
        try:
            while datetime.now() < end_time and self.running:
                # ç”ŸæˆæŒ‡æ ‡æ•°æ®
                metrics = self.generate_normal_metrics()
                
                # å¯èƒ½æ³¨å…¥å¼‚å¸¸
                injected_anomaly = None
                if inject_anomalies and random.random() < 0.2:  # 20%æ¦‚ç‡æ³¨å…¥å¼‚å¸¸
                    anomaly_type = random.choice(list(AnomalyType))
                    metrics, affected_metric, original_value, anomalous_value = self.inject_anomaly(metrics, anomaly_type)
                    injected_anomaly = {
                        'type': anomaly_type.value,
                        'metric': affected_metric,
                        'original_value': original_value,
                        'anomalous_value': anomalous_value
                    }
                
                # æ£€æµ‹å¼‚å¸¸
                detected_anomalies = self.detect_anomalies(metrics)
                
                # è®°å½•æ•°æ®
                data_point = {
                    'timestamp': datetime.now().isoformat(),
                    'metrics': metrics,
                    'detected_anomalies': [
                        {
                            'type': anomaly.anomaly_type.value,
                            'severity': anomaly.severity.value,
                            'metric_name': anomaly.metric_name,
                            'expected_value': anomaly.expected_value,
                            'actual_value': anomaly.actual_value,
                            'deviation_score': anomaly.deviation_score,
                            'confidence': anomaly.confidence,
                            'description': anomaly.description,
                            'context': anomaly.context
                        } for anomaly in detected_anomalies
                    ],
                    'injected_anomaly': injected_anomaly
                }
                
                self.metrics_history.append(data_point)
                self.anomalies.extend(detected_anomalies)
                
                # æ˜¾ç¤ºå®æ—¶ä¿¡æ¯
                anomaly_count = len(detected_anomalies)
                if anomaly_count > 0:
                    severity_counts = {}
                    for anomaly in detected_anomalies:
                        severity = anomaly.severity.value
                        severity_counts[severity] = severity_counts.get(severity, 0) + 1
                    
                    severity_str = ", ".join([f"{k}: {v}" for k, v in severity_counts.items()])
                    print(f"[{datetime.now().strftime('%H:%M:%S')}] "
                          f"æ£€æµ‹åˆ° {anomaly_count} ä¸ªå¼‚å¸¸ ({severity_str})")
                    
                    if injected_anomaly:
                        print(f"  â†³ æ³¨å…¥å¼‚å¸¸: {injected_anomaly['type']} in {injected_anomaly['metric']}")
                else:
                    print(f"[{datetime.now().strftime('%H:%M:%S')}] ç³»ç»Ÿæ­£å¸¸")
                
                time.sleep(self.detection_interval)
                
        except KeyboardInterrupt:
            print("\næ£€æµ‹è¢«ç”¨æˆ·ä¸­æ–­")
            self.running = False
        
        print(f"\nâœ… å¼‚å¸¸æ£€æµ‹å®Œæˆ")
        print(f"æ€»æ•°æ®ç‚¹: {len(self.metrics_history)}")
        print(f"æ£€æµ‹åˆ°å¼‚å¸¸: {len(self.anomalies)}")
        
        # ç»Ÿè®¡å¼‚å¸¸ç±»å‹
        anomaly_stats = {}
        severity_stats = {}
        for anomaly in self.anomalies:
            anomaly_type = anomaly.anomaly_type.value
            severity = anomaly.severity.value
            anomaly_stats[anomaly_type] = anomaly_stats.get(anomaly_type, 0) + 1
            severity_stats[severity] = severity_stats.get(severity, 0) + 1
        
        print("\nğŸ“Š å¼‚å¸¸ç»Ÿè®¡:")
        for anomaly_type, count in anomaly_stats.items():
            print(f"  {anomaly_type}: {count}")
        
        print("\nâš ï¸  ä¸¥é‡ç¨‹åº¦ç»Ÿè®¡:")
        for severity, count in severity_stats.items():
            print(f"  {severity}: {count}")
        
        # å¯¼å‡ºæ•°æ®
        if export_file:
            self.export_results(export_file, patterns, scenarios)
    
    def export_results(self, filename: str, patterns: List[Dict], scenarios: Dict):
        """
        å¯¼å‡ºæ£€æµ‹ç»“æœåˆ°JSONæ–‡ä»¶
        
        Args:
            filename: å¯¼å‡ºæ–‡ä»¶å
            patterns: å¼‚å¸¸æ¨¡å¼
            scenarios: åœºæ™¯ä¿¡æ¯
        """
        export_data = {
            'simulation_info': {
                'type': 'anomaly_detection',
                'start_time': self.start_time.isoformat(),
                'end_time': datetime.now().isoformat(),
                'duration': self.duration,
                'detection_interval': self.detection_interval,
                'data_points': len(self.metrics_history),
                'total_anomalies': len(self.anomalies)
            },
            'configuration': {
                'baselines': self.baselines,
                'thresholds': self.thresholds
            },
            'patterns': patterns,
            'scenarios': scenarios,
            'metrics_history': self.metrics_history,
            'summary': {
                'anomaly_types': {},
                'severity_distribution': {},
                'affected_metrics': {}
            }
        }
        
        # ç”Ÿæˆæ±‡æ€»ç»Ÿè®¡
        for anomaly in self.anomalies:
            anomaly_type = anomaly.anomaly_type.value
            severity = anomaly.severity.value
            metric_name = anomaly.metric_name
            
            export_data['summary']['anomaly_types'][anomaly_type] = \
                export_data['summary']['anomaly_types'].get(anomaly_type, 0) + 1
            export_data['summary']['severity_distribution'][severity] = \
                export_data['summary']['severity_distribution'].get(severity, 0) + 1
            export_data['summary']['affected_metrics'][metric_name] = \
                export_data['summary']['affected_metrics'].get(metric_name, 0) + 1
        
        os.makedirs(os.path.dirname(filename) if os.path.dirname(filename) else '.', exist_ok=True)
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(export_data, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ“Š å¼‚å¸¸æ£€æµ‹ç»“æœå·²å¯¼å‡ºåˆ°: {filename}")

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='å¼‚å¸¸æ£€æµ‹æ¨¡æ‹Ÿå™¨')
    parser.add_argument('--duration', type=int, default=300, help='æ£€æµ‹æ—¶é•¿(ç§’)')
    parser.add_argument('--interval', type=int, default=30, help='æ£€æµ‹é—´éš”(ç§’)')
    parser.add_argument('--export', type=str, help='å¯¼å‡ºæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--no-inject', action='store_true', help='ç¦ç”¨å¼‚å¸¸æ³¨å…¥')
    
    args = parser.parse_args()
    
    detector = AnomalyDetector(duration=args.duration, detection_interval=args.interval)
    detector.run_detection(export_file=args.export, inject_anomalies=not args.no_inject)

if __name__ == '__main__':
    main()