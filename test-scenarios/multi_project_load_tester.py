#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¤šé¡¹ç›®è´Ÿè½½æµ‹è¯•å™¨

è¿™ä¸ªè„šæœ¬æ‰©å±•äº†AIOpsæµ‹è¯•æ¡†æ¶ï¼Œæ”¯æŒå¤šç§ç¼–ç¨‹è¯­è¨€é¡¹ç›®çš„è´Ÿè½½æµ‹è¯•ï¼Œ
åŒ…æ‹¬æ„å»ºé”™è¯¯ã€è¿è¡Œæ—¶é”™è¯¯ã€æ€§èƒ½æµ‹è¯•ç­‰åœºæ™¯ã€‚

æ”¯æŒçš„é¡¹ç›®ç±»å‹ï¼š
- Javaé¡¹ç›® (Maven/Gradle)
- Rusté¡¹ç›® (Cargo)
- Node.jsé¡¹ç›® (npm/yarn)
- Pythoné¡¹ç›® (pip)
- .NETé¡¹ç›® (dotnet)
- Goé¡¹ç›® (go mod)

ä½œè€…: AIOpsæµ‹è¯•æ¡†æ¶
åˆ›å»ºæ—¶é—´: 2025-01-10
"""

import os
import sys
import json
import time
import random
import argparse
import subprocess
import threading
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Tuple

class ProjectLoadTester:
    """å¤šé¡¹ç›®è´Ÿè½½æµ‹è¯•å™¨ç±»"""
    
    def __init__(self):
        """åˆå§‹åŒ–æµ‹è¯•å™¨"""
        self.test_results = {}
        self.active_processes = []
        self.metrics = {
            'build_success': 0,
            'build_failure': 0,
            'runtime_success': 0,
            'runtime_failure': 0,
            'performance_tests': 0
        }
        
    def create_mock_java_project(self, project_name: str, introduce_error: bool = False) -> str:
        """åˆ›å»ºæ¨¡æ‹ŸJavaé¡¹ç›®"""
        project_dir = Path(f'mock_projects/java/{project_name}')
        project_dir.mkdir(parents=True, exist_ok=True)
        
        # åˆ›å»ºpom.xml
        pom_content = f'''
<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0"
         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 
         http://maven.apache.org/xsd/maven-4.0.0.xsd">
    <modelVersion>4.0.0</modelVersion>
    
    <groupId>com.aiops.test</groupId>
    <artifactId>{project_name}</artifactId>
    <version>1.0.0</version>
    <packaging>jar</packaging>
    
    <properties>
        <maven.compiler.source>11</maven.compiler.source>
        <maven.compiler.target>11</maven.compiler.target>
        <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
    </properties>
    
    <dependencies>
        <dependency>
            <groupId>junit</groupId>
            <artifactId>junit</artifactId>
            <version>4.13.2</version>
            <scope>test</scope>
        </dependency>
    </dependencies>
    
    <build>
        <plugins>
            <plugin>
                <groupId>org.apache.maven.plugins</groupId>
                <artifactId>maven-compiler-plugin</artifactId>
                <version>3.8.1</version>
            </plugin>
        </plugins>
    </build>
</project>
'''
        
        with open(project_dir / 'pom.xml', 'w', encoding='utf-8') as f:
            f.write(pom_content)
        
        # åˆ›å»ºJavaæºç 
        src_dir = project_dir / 'src/main/java/com/aiops/test'
        src_dir.mkdir(parents=True, exist_ok=True)
        
        # æ ¹æ®æ˜¯å¦å¼•å…¥é”™è¯¯åˆ›å»ºä¸åŒçš„ä»£ç 
        if introduce_error:
            java_content = f'''
package com.aiops.test;

public class {project_name.capitalize()}App {{
    public static void main(String[] args) {{
        System.out.println("Starting {project_name} application...");
        
        // æ•…æ„å¼•å…¥ç¼–è¯‘é”™è¯¯
        UndefinedClass obj = new UndefinedClass();
        obj.nonExistentMethod();
        
        System.out.println("Application completed.");
    }}
    
    public void performHeavyTask() {{
        // æ¨¡æ‹ŸCPUå¯†é›†å‹ä»»åŠ¡
        for (int i = 0; i < 1000000; i++) {{
            Math.sqrt(i * Math.random());
        }}
    }}
}}
'''
        else:
            java_content = f'''
package com.aiops.test;

import java.util.concurrent.TimeUnit;

public class {project_name.capitalize()}App {{
    public static void main(String[] args) {{
        System.out.println("Starting {project_name} application...");
        
        {project_name.capitalize()}App app = new {project_name.capitalize()}App();
        
        // æ¨¡æ‹Ÿä¸åŒç±»å‹çš„è´Ÿè½½
        app.performCpuTask();
        app.performMemoryTask();
        app.performIoTask();
        
        System.out.println("Application completed successfully.");
    }}
    
    public void performCpuTask() {{
        System.out.println("Performing CPU intensive task...");
        for (int i = 0; i < 500000; i++) {{
            Math.sqrt(i * Math.random());
        }}
    }}
    
    public void performMemoryTask() {{
        System.out.println("Performing memory intensive task...");
        java.util.List<String> data = new java.util.ArrayList<>();
        for (int i = 0; i < 100000; i++) {{
            data.add("Data item " + i);
        }}
        data.clear();
    }}
    
    public void performIoTask() {{
        System.out.println("Performing I/O task...");
        try {{
            TimeUnit.MILLISECONDS.sleep(100);
        }} catch (InterruptedException e) {{
            Thread.currentThread().interrupt();
        }}
    }}
}}
'''
        
        with open(src_dir / f'{project_name.capitalize()}App.java', 'w', encoding='utf-8') as f:
            f.write(java_content)
        
        return str(project_dir)
    
    def create_mock_rust_project(self, project_name: str, introduce_error: bool = False) -> str:
        """åˆ›å»ºæ¨¡æ‹ŸRusté¡¹ç›®"""
        project_dir = Path(f'mock_projects/rust/{project_name}')
        project_dir.mkdir(parents=True, exist_ok=True)
        
        # åˆ›å»ºCargo.toml
        cargo_content = f'''
[package]
name = "{project_name}"
version = "0.1.0"
edition = "2021"

[dependencies]
rand = "0.8"
tokio = {{ version = "1.0", features = ["full"] }}
'''
        
        with open(project_dir / 'Cargo.toml', 'w', encoding='utf-8') as f:
            f.write(cargo_content)
        
        # åˆ›å»ºsrcç›®å½•
        src_dir = project_dir / 'src'
        src_dir.mkdir(exist_ok=True)
        
        # æ ¹æ®æ˜¯å¦å¼•å…¥é”™è¯¯åˆ›å»ºä¸åŒçš„ä»£ç 
        if introduce_error:
            rust_content = f'''
use std::thread;
use std::time::Duration;

fn main() {{
    println!("Starting {project_name} application...");
    
    // æ•…æ„å¼•å…¥ç¼–è¯‘é”™è¯¯
    let undefined_var = some_undefined_function();
    println!("{{:?}}", undefined_var);
    
    println!("Application completed.");
}}

fn cpu_intensive_task() {{
    for i in 0..1000000 {{
        let _ = (i as f64).sqrt();
    }}
}}
'''
        else:
            rust_content = f'''
use rand::Rng;
use std::thread;
use std::time::Duration;
use tokio::time::sleep;

#[tokio::main]
async fn main() {{
    println!("Starting {project_name} application...");
    
    // å¹¶å‘æ‰§è¡Œä¸åŒç±»å‹çš„ä»»åŠ¡
    let cpu_task = tokio::spawn(cpu_intensive_task());
    let memory_task = tokio::spawn(memory_intensive_task());
    let io_task = tokio::spawn(io_intensive_task());
    
    // ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
    let _ = tokio::join!(cpu_task, memory_task, io_task);
    
    println!("Application completed successfully.");
}}

async fn cpu_intensive_task() {{
    println!("Performing CPU intensive task...");
    for i in 0..500000 {{
        let _ = (i as f64 * rand::thread_rng().gen::<f64>()).sqrt();
    }}
}}

async fn memory_intensive_task() {{
    println!("Performing memory intensive task...");
    let mut data: Vec<String> = Vec::new();
    for i in 0..100000 {{
        data.push(format!("Data item {{}}", i));
    }}
    data.clear();
}}

async fn io_intensive_task() {{
    println!("Performing I/O task...");
    sleep(Duration::from_millis(100)).await;
}}
'''
        
        with open(src_dir / 'main.rs', 'w', encoding='utf-8') as f:
            f.write(rust_content)
        
        return str(project_dir)
    
    def create_mock_nodejs_project(self, project_name: str, introduce_error: bool = False) -> str:
        """åˆ›å»ºæ¨¡æ‹ŸNode.jsé¡¹ç›®"""
        project_dir = Path(f'mock_projects/nodejs/{project_name}')
        project_dir.mkdir(parents=True, exist_ok=True)
        
        # åˆ›å»ºpackage.json
        package_content = {
            "name": project_name,
            "version": "1.0.0",
            "description": f"Mock {project_name} project for load testing",
            "main": "index.js",
            "scripts": {
                "start": "node index.js",
                "test": "echo \"Error: no test specified\" && exit 1"
            },
            "dependencies": {
                "express": "^4.18.0",
                "lodash": "^4.17.21"
            }
        }
        
        with open(project_dir / 'package.json', 'w', encoding='utf-8') as f:
            json.dump(package_content, f, indent=2)
        
        # æ ¹æ®æ˜¯å¦å¼•å…¥é”™è¯¯åˆ›å»ºä¸åŒçš„ä»£ç 
        if introduce_error:
            js_content = f'''
console.log('Starting {project_name} application...');

// æ•…æ„å¼•å…¥è¿è¡Œæ—¶é”™è¯¯
const undefinedModule = require('non-existent-module');
undefinedModule.someFunction();

console.log('Application completed.');
'''
        else:
            js_content = f'''
const express = require('express');
const _ = require('lodash');

console.log('Starting {project_name} application...');

const app = express();
const port = 3000 + Math.floor(Math.random() * 1000);

// CPUå¯†é›†å‹ä»»åŠ¡
function cpuIntensiveTask() {{
    console.log('Performing CPU intensive task...');
    for (let i = 0; i < 500000; i++) {{
        Math.sqrt(i * Math.random());
    }}
}}

// å†…å­˜å¯†é›†å‹ä»»åŠ¡
function memoryIntensiveTask() {{
    console.log('Performing memory intensive task...');
    const data = [];
    for (let i = 0; i < 100000; i++) {{
        data.push(`Data item ${{i}}`);
    }}
    data.length = 0;
}}

// I/Oå¯†é›†å‹ä»»åŠ¡
function ioIntensiveTask() {{
    console.log('Performing I/O task...');
    return new Promise(resolve => {{
        setTimeout(resolve, 100);
    }});
}}

async function runTasks() {{
    cpuIntensiveTask();
    memoryIntensiveTask();
    await ioIntensiveTask();
    
    console.log('All tasks completed successfully.');
    process.exit(0);
}}

// å¯åŠ¨ä»»åŠ¡
runTasks();
'''
        
        with open(project_dir / 'index.js', 'w', encoding='utf-8') as f:
            f.write(js_content)
        
        return str(project_dir)
    
    def run_build_test(self, project_type: str, project_path: str, project_name: str) -> Tuple[bool, str, float]:
        """è¿è¡Œæ„å»ºæµ‹è¯•"""
        start_time = time.time()
        
        try:
            if project_type == 'java':
                # Mavenæ„å»º
                result = subprocess.run(
                    ['mvn', 'clean', 'compile'],
                    cwd=project_path,
                    capture_output=True,
                    text=True,
                    timeout=120
                )
            elif project_type == 'rust':
                # Cargoæ„å»º
                result = subprocess.run(
                    ['cargo', 'build'],
                    cwd=project_path,
                    capture_output=True,
                    text=True,
                    timeout=120
                )
            elif project_type == 'nodejs':
                # npmå®‰è£…ä¾èµ–
                result = subprocess.run(
                    ['npm', 'install'],
                    cwd=project_path,
                    capture_output=True,
                    text=True,
                    timeout=120
                )
            else:
                return False, f"Unsupported project type: {project_type}", 0
            
            duration = time.time() - start_time
            success = result.returncode == 0
            
            if success:
                self.metrics['build_success'] += 1
            else:
                self.metrics['build_failure'] += 1
            
            return success, result.stderr if not success else "Build successful", duration
            
        except subprocess.TimeoutExpired:
            duration = time.time() - start_time
            self.metrics['build_failure'] += 1
            return False, "Build timeout", duration
        except Exception as e:
            duration = time.time() - start_time
            self.metrics['build_failure'] += 1
            return False, str(e), duration
    
    def run_runtime_test(self, project_type: str, project_path: str, project_name: str) -> Tuple[bool, str, float]:
        """è¿è¡Œè¿è¡Œæ—¶æµ‹è¯•"""
        start_time = time.time()
        
        try:
            if project_type == 'java':
                # è¿è¡ŒJavaåº”ç”¨
                result = subprocess.run(
                    ['mvn', 'exec:java', f'-Dexec.mainClass=com.aiops.test.{project_name.capitalize()}App'],
                    cwd=project_path,
                    capture_output=True,
                    text=True,
                    timeout=60
                )
            elif project_type == 'rust':
                # è¿è¡ŒRuståº”ç”¨
                result = subprocess.run(
                    ['cargo', 'run'],
                    cwd=project_path,
                    capture_output=True,
                    text=True,
                    timeout=60
                )
            elif project_type == 'nodejs':
                # è¿è¡ŒNode.jsåº”ç”¨
                result = subprocess.run(
                    ['node', 'index.js'],
                    cwd=project_path,
                    capture_output=True,
                    text=True,
                    timeout=60
                )
            else:
                return False, f"Unsupported project type: {project_type}", 0
            
            duration = time.time() - start_time
            success = result.returncode == 0
            
            if success:
                self.metrics['runtime_success'] += 1
            else:
                self.metrics['runtime_failure'] += 1
            
            return success, result.stderr if not success else "Runtime successful", duration
            
        except subprocess.TimeoutExpired:
            duration = time.time() - start_time
            self.metrics['runtime_failure'] += 1
            return False, "Runtime timeout", duration
        except Exception as e:
            duration = time.time() - start_time
            self.metrics['runtime_failure'] += 1
            return False, str(e), duration
    
    def run_concurrent_load_test(self, project_configs: List[Dict], duration: int = 300):
        """è¿è¡Œå¹¶å‘è´Ÿè½½æµ‹è¯•"""
        print(f"ğŸš€ å¼€å§‹å¤šé¡¹ç›®å¹¶å‘è´Ÿè½½æµ‹è¯• (æŒç»­æ—¶é—´: {duration}ç§’)")
        print(f"æµ‹è¯•é¡¹ç›®æ•°é‡: {len(project_configs)}")
        
        # åˆ›å»ºæ‰€æœ‰é¡¹ç›®
        projects = []
        for config in project_configs:
            project_type = config['type']
            project_name = config['name']
            introduce_error = config.get('introduce_error', False)
            
            print(f"ğŸ“ åˆ›å»º {project_type} é¡¹ç›®: {project_name}")
            
            if project_type == 'java':
                project_path = self.create_mock_java_project(project_name, introduce_error)
            elif project_type == 'rust':
                project_path = self.create_mock_rust_project(project_name, introduce_error)
            elif project_type == 'nodejs':
                project_path = self.create_mock_nodejs_project(project_name, introduce_error)
            else:
                print(f"âŒ ä¸æ”¯æŒçš„é¡¹ç›®ç±»å‹: {project_type}")
                continue
            
            projects.append({
                'type': project_type,
                'name': project_name,
                'path': project_path,
                'introduce_error': introduce_error
            })
        
        # å¼€å§‹è´Ÿè½½æµ‹è¯•
        start_time = time.time()
        end_time = start_time + duration
        
        test_cycle = 0
        while time.time() < end_time:
            test_cycle += 1
            print(f"\nğŸ”„ æµ‹è¯•å‘¨æœŸ {test_cycle}")
            
            # å¹¶å‘æµ‹è¯•æ‰€æœ‰é¡¹ç›®
            threads = []
            for project in projects:
                thread = threading.Thread(
                    target=self._test_project_cycle,
                    args=(project, test_cycle)
                )
                threads.append(thread)
                thread.start()
            
            # ç­‰å¾…æ‰€æœ‰çº¿ç¨‹å®Œæˆ
            for thread in threads:
                thread.join()
            
            # éšæœºç­‰å¾…é—´éš”
            time.sleep(random.uniform(5, 15))
        
        total_duration = time.time() - start_time
        print(f"\nâœ… è´Ÿè½½æµ‹è¯•å®Œæˆï¼Œæ€»è€—æ—¶: {total_duration:.2f}ç§’")
        
        # ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
        self._generate_load_test_report(total_duration, test_cycle)
    
    def _test_project_cycle(self, project: Dict, cycle: int):
        """å•ä¸ªé¡¹ç›®çš„æµ‹è¯•å‘¨æœŸ"""
        project_type = project['type']
        project_name = project['name']
        project_path = project['path']
        
        print(f"  ğŸ”¨ [{project_type}] {project_name} - æ„å»ºæµ‹è¯•")
        build_success, build_msg, build_duration = self.run_build_test(
            project_type, project_path, project_name
        )
        
        if build_success:
            print(f"  ğŸƒ [{project_type}] {project_name} - è¿è¡Œæ—¶æµ‹è¯•")
            runtime_success, runtime_msg, runtime_duration = self.run_runtime_test(
                project_type, project_path, project_name
            )
        else:
            runtime_success = False
            runtime_msg = "Skipped due to build failure"
            runtime_duration = 0
        
        # è®°å½•æµ‹è¯•ç»“æœ
        test_key = f"{project_name}_cycle_{cycle}"
        self.test_results[test_key] = {
            'project_type': project_type,
            'project_name': project_name,
            'cycle': cycle,
            'build_success': build_success,
            'build_duration': build_duration,
            'build_message': build_msg,
            'runtime_success': runtime_success,
            'runtime_duration': runtime_duration,
            'runtime_message': runtime_msg,
            'total_duration': build_duration + runtime_duration
        }
        
        status = "âœ…" if build_success and runtime_success else "âŒ"
        print(f"  {status} [{project_type}] {project_name} - å‘¨æœŸå®Œæˆ ({build_duration + runtime_duration:.2f}s)")
    
    def _generate_load_test_report(self, total_duration: float, total_cycles: int):
        """ç”Ÿæˆè´Ÿè½½æµ‹è¯•æŠ¥å‘Š"""
        print("\n" + "="*80)
        print("ğŸ“Š å¤šé¡¹ç›®è´Ÿè½½æµ‹è¯•æŠ¥å‘Š")
        print("="*80)
        
        print(f"æ€»æµ‹è¯•æ—¶é—´: {total_duration:.2f} ç§’")
        print(f"æµ‹è¯•å‘¨æœŸæ•°: {total_cycles}")
        print(f"æ„å»ºæˆåŠŸ: {self.metrics['build_success']}")
        print(f"æ„å»ºå¤±è´¥: {self.metrics['build_failure']}")
        print(f"è¿è¡ŒæˆåŠŸ: {self.metrics['runtime_success']}")
        print(f"è¿è¡Œå¤±è´¥: {self.metrics['runtime_failure']}")
        
        total_tests = sum(self.metrics.values())
        if total_tests > 0:
            success_rate = ((self.metrics['build_success'] + self.metrics['runtime_success']) / total_tests) * 100
            print(f"æ€»ä½“æˆåŠŸç‡: {success_rate:.1f}%")
        
        # æŒ‰é¡¹ç›®ç±»å‹ç»Ÿè®¡
        project_stats = {}
        for result in self.test_results.values():
            project_type = result['project_type']
            if project_type not in project_stats:
                project_stats[project_type] = {
                    'build_success': 0,
                    'build_failure': 0,
                    'runtime_success': 0,
                    'runtime_failure': 0,
                    'avg_build_time': 0,
                    'avg_runtime_time': 0,
                    'count': 0
                }
            
            stats = project_stats[project_type]
            stats['count'] += 1
            
            if result['build_success']:
                stats['build_success'] += 1
            else:
                stats['build_failure'] += 1
            
            if result['runtime_success']:
                stats['runtime_success'] += 1
            else:
                stats['runtime_failure'] += 1
            
            stats['avg_build_time'] += result['build_duration']
            stats['avg_runtime_time'] += result['runtime_duration']
        
        print("\nğŸ“ˆ æŒ‰é¡¹ç›®ç±»å‹ç»Ÿè®¡:")
        for project_type, stats in project_stats.items():
            if stats['count'] > 0:
                avg_build = stats['avg_build_time'] / stats['count']
                avg_runtime = stats['avg_runtime_time'] / stats['count']
                print(f"  {project_type.upper()}:")
                print(f"    æ„å»º: {stats['build_success']}æˆåŠŸ/{stats['build_failure']}å¤±è´¥ (å¹³å‡{avg_build:.2f}s)")
                print(f"    è¿è¡Œ: {stats['runtime_success']}æˆåŠŸ/{stats['runtime_failure']}å¤±è´¥ (å¹³å‡{avg_runtime:.2f}s)")
        
        # ä¿å­˜è¯¦ç»†æŠ¥å‘Š
        report_data = {
            'test_type': 'å¤šé¡¹ç›®è´Ÿè½½æµ‹è¯•',
            'start_time': datetime.now().isoformat(),
            'total_duration': total_duration,
            'total_cycles': total_cycles,
            'metrics': self.metrics,
            'project_statistics': project_stats,
            'detailed_results': self.test_results
        }
        
        # åˆ›å»ºæŠ¥å‘Šç›®å½•
        report_dir = Path('load_test_reports')
        report_dir.mkdir(exist_ok=True)
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        report_file = report_dir / f'multi_project_load_test_{timestamp}.json'
        
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report_data, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='å¤šé¡¹ç›®è´Ÿè½½æµ‹è¯•å™¨')
    parser.add_argument(
        '--duration',
        type=int,
        default=300,
        help='æµ‹è¯•æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤300ç§’'
    )
    parser.add_argument(
        '--config',
        type=str,
        help='é¡¹ç›®é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆJSONæ ¼å¼ï¼‰'
    )
    parser.add_argument(
        '--preset',
        choices=['basic', 'comprehensive', 'error-prone'],
        default='basic',
        help='é¢„è®¾é…ç½®: basic=åŸºç¡€æµ‹è¯•, comprehensive=å…¨é¢æµ‹è¯•, error-prone=é”™è¯¯åœºæ™¯æµ‹è¯•'
    )
    
    args = parser.parse_args()
    
    tester = ProjectLoadTester()
    
    # æ ¹æ®é¢„è®¾æˆ–é…ç½®æ–‡ä»¶ç¡®å®šé¡¹ç›®é…ç½®
    if args.config:
        with open(args.config, 'r', encoding='utf-8') as f:
            project_configs = json.load(f)
    else:
        if args.preset == 'basic':
            project_configs = [
                {'type': 'java', 'name': 'basic-java-app', 'introduce_error': False},
                {'type': 'rust', 'name': 'basic-rust-app', 'introduce_error': False},
                {'type': 'nodejs', 'name': 'basic-node-app', 'introduce_error': False}
            ]
        elif args.preset == 'comprehensive':
            project_configs = [
                {'type': 'java', 'name': 'web-service', 'introduce_error': False},
                {'type': 'java', 'name': 'batch-processor', 'introduce_error': False},
                {'type': 'rust', 'name': 'high-performance-api', 'introduce_error': False},
                {'type': 'rust', 'name': 'data-processor', 'introduce_error': False},
                {'type': 'nodejs', 'name': 'express-api', 'introduce_error': False},
                {'type': 'nodejs', 'name': 'websocket-server', 'introduce_error': False}
            ]
        elif args.preset == 'error-prone':
            project_configs = [
                {'type': 'java', 'name': 'buggy-java-app', 'introduce_error': True},
                {'type': 'rust', 'name': 'failing-rust-app', 'introduce_error': True},
                {'type': 'nodejs', 'name': 'broken-node-app', 'introduce_error': True},
                {'type': 'java', 'name': 'stable-java-app', 'introduce_error': False},
                {'type': 'rust', 'name': 'stable-rust-app', 'introduce_error': False}
            ]
    
    # è¿è¡Œè´Ÿè½½æµ‹è¯•
    tester.run_concurrent_load_test(project_configs, args.duration)

if __name__ == '__main__':
    main()